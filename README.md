# Mistral Reasoning Fine-Tuning

Finetuned a Mistral-7B-Instruct model using PEFT (LoRA) and Unsloth for chain-of-thought (CoT) and reasoning tasks via SFT. Plan to try GRPO and DPO soon to improve performance.

![](https://github.com/hamsar4j/mistral-reasoning-ft/blob/main/assets/mistral-ft.png)
